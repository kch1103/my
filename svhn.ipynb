{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled31.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN0LzPXCg8RgW290weWt8dr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kch1103/my/blob/main/svhn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9iVKdztqYJW"
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import torchvision.transforms as transforms \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import loadmat \n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "from torchvision.datasets import SVHN"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bDcmYLXqaHs",
        "outputId": "576885fa-c3df-449c-f45e-983e01b29b9f"
      },
      "source": [
        "resnet18_pretrained = models.resnet18(pretrained = True)\n",
        "print(resnet18_pretrained)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmHy3ejSqjiL"
      },
      "source": [
        "svhn_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RjkDN7crCoc",
        "outputId": "d8a678e5-d8ab-4fbf-aa7a-41ab27bbfdcb"
      },
      "source": [
        "train_set = SVHN(\n",
        "    root = './data',\n",
        "    split = 'train',\n",
        "    download = True,\n",
        "    transform = svhn_transform\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./data/train_32x32.mat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZfz9Zz2sRqy",
        "outputId": "3216bbf6-7411-4593-cb13-96d0554642a0"
      },
      "source": [
        "test_set = SVHN(\n",
        "    root = './data',\n",
        "    split = 'test',\n",
        "    download = True,\n",
        "    transform = svhn_transform\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./data/test_32x32.mat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB6GabC5tokZ"
      },
      "source": [
        "train_data = torch.utils.data.DataLoader(dataset = train_set,\n",
        "                                         batch_size = 10,\n",
        "                                         shuffle = True)\n",
        "\n",
        "test_data = torch.utils.data.DataLoader(dataset = test_set,\n",
        "                                        batch_size = 10,\n",
        "                                        shuffle = True) \n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31SfI_pauDeC"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0EtkPGfuHmS"
      },
      "source": [
        "num_classes = 10\n",
        "num_ftrs = resnet18_pretrained.fc.in_features\n",
        "resnet18_pretrained.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "resnet18_pretrained.to(device)\n",
        "model = resnet18_pretrained"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpTKQaLVuJHC"
      },
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 2\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIiYCO5iuRbR",
        "outputId": "a517b1ab-b71f-4d50-a577-8b1c7646604d"
      },
      "source": [
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_data, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:   \n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 10))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    10] loss: 3.301\n",
            "[1,    20] loss: 2.722\n",
            "[1,    30] loss: 3.025\n",
            "[1,    40] loss: 2.615\n",
            "[1,    50] loss: 2.683\n",
            "[1,    60] loss: 2.194\n",
            "[1,    70] loss: 2.533\n",
            "[1,    80] loss: 2.248\n",
            "[1,    90] loss: 2.161\n",
            "[1,   100] loss: 2.357\n",
            "[1,   110] loss: 2.264\n",
            "[1,   120] loss: 2.133\n",
            "[1,   130] loss: 2.092\n",
            "[1,   140] loss: 2.241\n",
            "[1,   150] loss: 2.146\n",
            "[1,   160] loss: 2.142\n",
            "[1,   170] loss: 2.037\n",
            "[1,   180] loss: 2.198\n",
            "[1,   190] loss: 2.038\n",
            "[1,   200] loss: 2.191\n",
            "[1,   210] loss: 2.091\n",
            "[1,   220] loss: 2.059\n",
            "[1,   230] loss: 2.389\n",
            "[1,   240] loss: 2.051\n",
            "[1,   250] loss: 2.111\n",
            "[1,   260] loss: 2.109\n",
            "[1,   270] loss: 2.088\n",
            "[1,   280] loss: 2.177\n",
            "[1,   290] loss: 2.073\n",
            "[1,   300] loss: 1.992\n",
            "[1,   310] loss: 2.119\n",
            "[1,   320] loss: 1.841\n",
            "[1,   330] loss: 2.016\n",
            "[1,   340] loss: 2.049\n",
            "[1,   350] loss: 2.028\n",
            "[1,   360] loss: 2.066\n",
            "[1,   370] loss: 1.729\n",
            "[1,   380] loss: 1.562\n",
            "[1,   390] loss: 1.616\n",
            "[1,   400] loss: 1.889\n",
            "[1,   410] loss: 1.815\n",
            "[1,   420] loss: 1.644\n",
            "[1,   430] loss: 1.741\n",
            "[1,   440] loss: 1.902\n",
            "[1,   450] loss: 1.822\n",
            "[1,   460] loss: 1.890\n",
            "[1,   470] loss: 1.457\n",
            "[1,   480] loss: 1.607\n",
            "[1,   490] loss: 1.575\n",
            "[1,   500] loss: 1.678\n",
            "[1,   510] loss: 1.747\n",
            "[1,   520] loss: 1.975\n",
            "[1,   530] loss: 1.756\n",
            "[1,   540] loss: 1.729\n",
            "[1,   550] loss: 1.453\n",
            "[1,   560] loss: 1.629\n",
            "[1,   570] loss: 1.498\n",
            "[1,   580] loss: 1.471\n",
            "[1,   590] loss: 1.636\n",
            "[1,   600] loss: 1.656\n",
            "[1,   610] loss: 1.625\n",
            "[1,   620] loss: 1.814\n",
            "[1,   630] loss: 1.668\n",
            "[1,   640] loss: 1.574\n",
            "[1,   650] loss: 1.727\n",
            "[1,   660] loss: 1.699\n",
            "[1,   670] loss: 1.597\n",
            "[1,   680] loss: 1.815\n",
            "[1,   690] loss: 1.375\n",
            "[1,   700] loss: 2.035\n",
            "[1,   710] loss: 1.665\n",
            "[1,   720] loss: 1.797\n",
            "[1,   730] loss: 2.006\n",
            "[1,   740] loss: 1.874\n",
            "[1,   750] loss: 1.866\n",
            "[1,   760] loss: 1.718\n",
            "[1,   770] loss: 1.726\n",
            "[1,   780] loss: 1.450\n",
            "[1,   790] loss: 1.750\n",
            "[1,   800] loss: 1.619\n",
            "[1,   810] loss: 1.616\n",
            "[1,   820] loss: 1.713\n",
            "[1,   830] loss: 1.358\n",
            "[1,   840] loss: 1.341\n",
            "[1,   850] loss: 1.499\n",
            "[1,   860] loss: 1.421\n",
            "[1,   870] loss: 1.725\n",
            "[1,   880] loss: 1.536\n",
            "[1,   890] loss: 1.782\n",
            "[1,   900] loss: 1.630\n",
            "[1,   910] loss: 1.667\n",
            "[1,   920] loss: 1.412\n",
            "[1,   930] loss: 1.380\n",
            "[1,   940] loss: 1.547\n",
            "[1,   950] loss: 1.432\n",
            "[1,   960] loss: 1.619\n",
            "[1,   970] loss: 1.460\n",
            "[1,   980] loss: 1.572\n",
            "[1,   990] loss: 1.507\n",
            "[1,  1000] loss: 1.256\n",
            "[1,  1010] loss: 1.288\n",
            "[1,  1020] loss: 1.655\n",
            "[1,  1030] loss: 1.299\n",
            "[1,  1040] loss: 1.441\n",
            "[1,  1050] loss: 1.230\n",
            "[1,  1060] loss: 1.064\n",
            "[1,  1070] loss: 1.117\n",
            "[1,  1080] loss: 1.436\n",
            "[1,  1090] loss: 1.352\n",
            "[1,  1100] loss: 1.313\n",
            "[1,  1110] loss: 1.126\n",
            "[1,  1120] loss: 1.570\n",
            "[1,  1130] loss: 1.384\n",
            "[1,  1140] loss: 1.330\n",
            "[1,  1150] loss: 1.225\n",
            "[1,  1160] loss: 1.284\n",
            "[1,  1170] loss: 1.188\n",
            "[1,  1180] loss: 1.649\n",
            "[1,  1190] loss: 1.165\n",
            "[1,  1200] loss: 1.162\n",
            "[1,  1210] loss: 1.207\n",
            "[1,  1220] loss: 1.426\n",
            "[1,  1230] loss: 1.120\n",
            "[1,  1240] loss: 1.277\n",
            "[1,  1250] loss: 1.269\n",
            "[1,  1260] loss: 0.823\n",
            "[1,  1270] loss: 1.101\n",
            "[1,  1280] loss: 1.114\n",
            "[1,  1290] loss: 1.248\n",
            "[1,  1300] loss: 1.503\n",
            "[1,  1310] loss: 1.333\n",
            "[1,  1320] loss: 1.308\n",
            "[1,  1330] loss: 1.364\n",
            "[1,  1340] loss: 1.233\n",
            "[1,  1350] loss: 1.114\n",
            "[1,  1360] loss: 1.042\n",
            "[1,  1370] loss: 0.855\n",
            "[1,  1380] loss: 1.125\n",
            "[1,  1390] loss: 1.198\n",
            "[1,  1400] loss: 1.311\n",
            "[1,  1410] loss: 1.229\n",
            "[1,  1420] loss: 1.227\n",
            "[1,  1430] loss: 1.180\n",
            "[1,  1440] loss: 1.352\n",
            "[1,  1450] loss: 1.334\n",
            "[1,  1460] loss: 1.090\n",
            "[1,  1470] loss: 1.155\n",
            "[1,  1480] loss: 1.163\n",
            "[1,  1490] loss: 1.297\n",
            "[1,  1500] loss: 1.459\n",
            "[1,  1510] loss: 1.091\n",
            "[1,  1520] loss: 1.338\n",
            "[1,  1530] loss: 1.255\n",
            "[1,  1540] loss: 1.094\n",
            "[1,  1550] loss: 0.909\n",
            "[1,  1560] loss: 1.149\n",
            "[1,  1570] loss: 0.938\n",
            "[1,  1580] loss: 1.098\n",
            "[1,  1590] loss: 1.215\n",
            "[1,  1600] loss: 0.964\n",
            "[1,  1610] loss: 1.110\n",
            "[1,  1620] loss: 0.845\n",
            "[1,  1630] loss: 1.074\n",
            "[1,  1640] loss: 1.088\n",
            "[1,  1650] loss: 1.275\n",
            "[1,  1660] loss: 1.182\n",
            "[1,  1670] loss: 0.765\n",
            "[1,  1680] loss: 1.055\n",
            "[1,  1690] loss: 0.865\n",
            "[1,  1700] loss: 1.082\n",
            "[1,  1710] loss: 1.200\n",
            "[1,  1720] loss: 1.203\n",
            "[1,  1730] loss: 0.991\n",
            "[1,  1740] loss: 1.051\n",
            "[1,  1750] loss: 1.174\n",
            "[1,  1760] loss: 1.218\n",
            "[1,  1770] loss: 1.130\n",
            "[1,  1780] loss: 0.909\n",
            "[1,  1790] loss: 0.750\n",
            "[1,  1800] loss: 1.102\n",
            "[1,  1810] loss: 0.718\n",
            "[1,  1820] loss: 1.022\n",
            "[1,  1830] loss: 1.035\n",
            "[1,  1840] loss: 1.060\n",
            "[1,  1850] loss: 0.946\n",
            "[1,  1860] loss: 1.018\n",
            "[1,  1870] loss: 1.032\n",
            "[1,  1880] loss: 0.968\n",
            "[1,  1890] loss: 0.987\n",
            "[1,  1900] loss: 1.066\n",
            "[1,  1910] loss: 0.766\n",
            "[1,  1920] loss: 0.838\n",
            "[1,  1930] loss: 1.027\n",
            "[1,  1940] loss: 1.069\n",
            "[1,  1950] loss: 1.034\n",
            "[1,  1960] loss: 1.152\n",
            "[1,  1970] loss: 1.054\n",
            "[1,  1980] loss: 0.857\n",
            "[1,  1990] loss: 1.054\n",
            "[1,  2000] loss: 0.790\n",
            "[1,  2010] loss: 0.981\n",
            "[1,  2020] loss: 1.016\n",
            "[1,  2030] loss: 1.222\n",
            "[1,  2040] loss: 1.116\n",
            "[1,  2050] loss: 0.928\n",
            "[1,  2060] loss: 0.999\n",
            "[1,  2070] loss: 0.656\n",
            "[1,  2080] loss: 0.785\n",
            "[1,  2090] loss: 0.838\n",
            "[1,  2100] loss: 0.885\n",
            "[1,  2110] loss: 1.006\n",
            "[1,  2120] loss: 0.839\n",
            "[1,  2130] loss: 0.795\n",
            "[1,  2140] loss: 0.851\n",
            "[1,  2150] loss: 0.964\n",
            "[1,  2160] loss: 1.080\n",
            "[1,  2170] loss: 0.994\n",
            "[1,  2180] loss: 0.882\n",
            "[1,  2190] loss: 0.713\n",
            "[1,  2200] loss: 0.760\n",
            "[1,  2210] loss: 0.939\n",
            "[1,  2220] loss: 0.957\n",
            "[1,  2230] loss: 0.885\n",
            "[1,  2240] loss: 0.805\n",
            "[1,  2250] loss: 0.926\n",
            "[1,  2260] loss: 0.761\n",
            "[1,  2270] loss: 0.875\n",
            "[1,  2280] loss: 0.797\n",
            "[1,  2290] loss: 0.853\n",
            "[1,  2300] loss: 0.863\n",
            "[1,  2310] loss: 0.930\n",
            "[1,  2320] loss: 0.688\n",
            "[1,  2330] loss: 0.658\n",
            "[1,  2340] loss: 0.753\n",
            "[1,  2350] loss: 0.996\n",
            "[1,  2360] loss: 0.898\n",
            "[1,  2370] loss: 0.737\n",
            "[1,  2380] loss: 0.928\n",
            "[1,  2390] loss: 0.660\n",
            "[1,  2400] loss: 1.058\n",
            "[1,  2410] loss: 0.893\n",
            "[1,  2420] loss: 1.218\n",
            "[1,  2430] loss: 1.008\n",
            "[1,  2440] loss: 0.979\n",
            "[1,  2450] loss: 0.811\n",
            "[1,  2460] loss: 0.679\n",
            "[1,  2470] loss: 0.800\n",
            "[1,  2480] loss: 0.883\n",
            "[1,  2490] loss: 0.832\n",
            "[1,  2500] loss: 0.709\n",
            "[1,  2510] loss: 0.761\n",
            "[1,  2520] loss: 0.914\n",
            "[1,  2530] loss: 0.857\n",
            "[1,  2540] loss: 0.893\n",
            "[1,  2550] loss: 0.683\n",
            "[1,  2560] loss: 0.944\n",
            "[1,  2570] loss: 0.723\n",
            "[1,  2580] loss: 0.821\n",
            "[1,  2590] loss: 0.810\n",
            "[1,  2600] loss: 0.869\n",
            "[1,  2610] loss: 0.843\n",
            "[1,  2620] loss: 0.863\n",
            "[1,  2630] loss: 0.743\n",
            "[1,  2640] loss: 0.791\n",
            "[1,  2650] loss: 0.732\n",
            "[1,  2660] loss: 0.982\n",
            "[1,  2670] loss: 0.731\n",
            "[1,  2680] loss: 0.799\n",
            "[1,  2690] loss: 1.003\n",
            "[1,  2700] loss: 0.678\n",
            "[1,  2710] loss: 0.734\n",
            "[1,  2720] loss: 1.057\n",
            "[1,  2730] loss: 0.939\n",
            "[1,  2740] loss: 0.900\n",
            "[1,  2750] loss: 0.737\n",
            "[1,  2760] loss: 0.505\n",
            "[1,  2770] loss: 0.964\n",
            "[1,  2780] loss: 0.682\n",
            "[1,  2790] loss: 0.469\n",
            "[1,  2800] loss: 0.749\n",
            "[1,  2810] loss: 0.718\n",
            "[1,  2820] loss: 0.928\n",
            "[1,  2830] loss: 0.768\n",
            "[1,  2840] loss: 0.783\n",
            "[1,  2850] loss: 0.744\n",
            "[1,  2860] loss: 0.898\n",
            "[1,  2870] loss: 0.901\n",
            "[1,  2880] loss: 1.056\n",
            "[1,  2890] loss: 0.795\n",
            "[1,  2900] loss: 0.843\n",
            "[1,  2910] loss: 0.751\n",
            "[1,  2920] loss: 0.832\n",
            "[1,  2930] loss: 0.976\n",
            "[1,  2940] loss: 0.702\n",
            "[1,  2950] loss: 0.728\n",
            "[1,  2960] loss: 0.798\n",
            "[1,  2970] loss: 0.761\n",
            "[1,  2980] loss: 0.764\n",
            "[1,  2990] loss: 0.558\n",
            "[1,  3000] loss: 0.511\n",
            "[1,  3010] loss: 0.747\n",
            "[1,  3020] loss: 0.683\n",
            "[1,  3030] loss: 0.711\n",
            "[1,  3040] loss: 0.895\n",
            "[1,  3050] loss: 0.644\n",
            "[1,  3060] loss: 0.735\n",
            "[1,  3070] loss: 0.681\n",
            "[1,  3080] loss: 0.744\n",
            "[1,  3090] loss: 0.762\n",
            "[1,  3100] loss: 0.781\n",
            "[1,  3110] loss: 0.900\n",
            "[1,  3120] loss: 0.631\n",
            "[1,  3130] loss: 0.813\n",
            "[1,  3140] loss: 0.786\n",
            "[1,  3150] loss: 0.540\n",
            "[1,  3160] loss: 0.717\n",
            "[1,  3170] loss: 0.599\n",
            "[1,  3180] loss: 0.724\n",
            "[1,  3190] loss: 0.766\n",
            "[1,  3200] loss: 1.008\n",
            "[1,  3210] loss: 0.807\n",
            "[1,  3220] loss: 0.690\n",
            "[1,  3230] loss: 0.760\n",
            "[1,  3240] loss: 0.629\n",
            "[1,  3250] loss: 0.709\n",
            "[1,  3260] loss: 0.676\n",
            "[1,  3270] loss: 0.921\n",
            "[1,  3280] loss: 0.563\n",
            "[1,  3290] loss: 0.814\n",
            "[1,  3300] loss: 0.635\n",
            "[1,  3310] loss: 0.882\n",
            "[1,  3320] loss: 1.044\n",
            "[1,  3330] loss: 0.762\n",
            "[1,  3340] loss: 0.606\n",
            "[1,  3350] loss: 0.710\n",
            "[1,  3360] loss: 0.741\n",
            "[1,  3370] loss: 0.751\n",
            "[1,  3380] loss: 0.394\n",
            "[1,  3390] loss: 0.589\n",
            "[1,  3400] loss: 0.589\n",
            "[1,  3410] loss: 0.506\n",
            "[1,  3420] loss: 0.672\n",
            "[1,  3430] loss: 0.462\n",
            "[1,  3440] loss: 0.843\n",
            "[1,  3450] loss: 0.803\n",
            "[1,  3460] loss: 0.814\n",
            "[1,  3470] loss: 0.891\n",
            "[1,  3480] loss: 1.083\n",
            "[1,  3490] loss: 0.745\n",
            "[1,  3500] loss: 0.597\n",
            "[1,  3510] loss: 0.643\n",
            "[1,  3520] loss: 0.686\n",
            "[1,  3530] loss: 0.517\n",
            "[1,  3540] loss: 0.700\n",
            "[1,  3550] loss: 0.615\n",
            "[1,  3560] loss: 0.480\n",
            "[1,  3570] loss: 0.352\n",
            "[1,  3580] loss: 0.554\n",
            "[1,  3590] loss: 0.627\n",
            "[1,  3600] loss: 0.694\n",
            "[1,  3610] loss: 0.778\n",
            "[1,  3620] loss: 0.449\n",
            "[1,  3630] loss: 0.642\n",
            "[1,  3640] loss: 0.787\n",
            "[1,  3650] loss: 0.592\n",
            "[1,  3660] loss: 0.616\n",
            "[1,  3670] loss: 0.552\n",
            "[1,  3680] loss: 0.623\n",
            "[1,  3690] loss: 0.729\n",
            "[1,  3700] loss: 0.516\n",
            "[1,  3710] loss: 0.543\n",
            "[1,  3720] loss: 0.607\n",
            "[1,  3730] loss: 0.708\n",
            "[1,  3740] loss: 0.807\n",
            "[1,  3750] loss: 0.515\n",
            "[1,  3760] loss: 0.592\n",
            "[1,  3770] loss: 0.805\n",
            "[1,  3780] loss: 0.820\n",
            "[1,  3790] loss: 0.624\n",
            "[1,  3800] loss: 0.787\n",
            "[1,  3810] loss: 0.790\n",
            "[1,  3820] loss: 0.468\n",
            "[1,  3830] loss: 0.590\n",
            "[1,  3840] loss: 0.703\n",
            "[1,  3850] loss: 0.429\n",
            "[1,  3860] loss: 0.814\n",
            "[1,  3870] loss: 0.725\n",
            "[1,  3880] loss: 1.153\n",
            "[1,  3890] loss: 0.680\n",
            "[1,  3900] loss: 0.598\n",
            "[1,  3910] loss: 0.884\n",
            "[1,  3920] loss: 0.723\n",
            "[1,  3930] loss: 0.997\n",
            "[1,  3940] loss: 0.649\n",
            "[1,  3950] loss: 0.813\n",
            "[1,  3960] loss: 0.676\n",
            "[1,  3970] loss: 0.706\n",
            "[1,  3980] loss: 0.955\n",
            "[1,  3990] loss: 0.790\n",
            "[1,  4000] loss: 0.652\n",
            "[1,  4010] loss: 0.561\n",
            "[1,  4020] loss: 0.656\n",
            "[1,  4030] loss: 0.673\n",
            "[1,  4040] loss: 0.815\n",
            "[1,  4050] loss: 0.794\n",
            "[1,  4060] loss: 0.955\n",
            "[1,  4070] loss: 1.151\n",
            "[1,  4080] loss: 1.232\n",
            "[1,  4090] loss: 0.810\n",
            "[1,  4100] loss: 0.745\n",
            "[1,  4110] loss: 0.799\n",
            "[1,  4120] loss: 0.640\n",
            "[1,  4130] loss: 0.593\n",
            "[1,  4140] loss: 0.696\n",
            "[1,  4150] loss: 0.781\n",
            "[1,  4160] loss: 0.701\n",
            "[1,  4170] loss: 0.942\n",
            "[1,  4180] loss: 0.635\n",
            "[1,  4190] loss: 0.890\n",
            "[1,  4200] loss: 0.655\n",
            "[1,  4210] loss: 0.703\n",
            "[1,  4220] loss: 0.576\n",
            "[1,  4230] loss: 0.797\n",
            "[1,  4240] loss: 0.609\n",
            "[1,  4250] loss: 0.672\n",
            "[1,  4260] loss: 0.510\n",
            "[1,  4270] loss: 0.569\n",
            "[1,  4280] loss: 0.833\n",
            "[1,  4290] loss: 0.892\n",
            "[1,  4300] loss: 0.830\n",
            "[1,  4310] loss: 0.845\n",
            "[1,  4320] loss: 0.806\n",
            "[1,  4330] loss: 0.880\n",
            "[1,  4340] loss: 0.854\n",
            "[1,  4350] loss: 0.560\n",
            "[1,  4360] loss: 0.855\n",
            "[1,  4370] loss: 0.894\n",
            "[1,  4380] loss: 0.798\n",
            "[1,  4390] loss: 0.521\n",
            "[1,  4400] loss: 0.674\n",
            "[1,  4410] loss: 0.866\n",
            "[1,  4420] loss: 0.562\n",
            "[1,  4430] loss: 0.832\n",
            "[1,  4440] loss: 0.716\n",
            "[1,  4450] loss: 0.378\n",
            "[1,  4460] loss: 0.493\n",
            "[1,  4470] loss: 0.587\n",
            "[1,  4480] loss: 0.544\n",
            "[1,  4490] loss: 0.662\n",
            "[1,  4500] loss: 0.554\n",
            "[1,  4510] loss: 0.842\n",
            "[1,  4520] loss: 0.703\n",
            "[1,  4530] loss: 0.483\n",
            "[1,  4540] loss: 0.719\n",
            "[1,  4550] loss: 0.585\n",
            "[1,  4560] loss: 0.909\n",
            "[1,  4570] loss: 0.802\n",
            "[1,  4580] loss: 0.913\n",
            "[1,  4590] loss: 0.510\n",
            "[1,  4600] loss: 0.501\n",
            "[1,  4610] loss: 0.547\n",
            "[1,  4620] loss: 0.580\n",
            "[1,  4630] loss: 0.748\n",
            "[1,  4640] loss: 0.461\n",
            "[1,  4650] loss: 0.869\n",
            "[1,  4660] loss: 0.601\n",
            "[1,  4670] loss: 0.616\n",
            "[1,  4680] loss: 0.813\n",
            "[1,  4690] loss: 0.390\n",
            "[1,  4700] loss: 0.727\n",
            "[1,  4710] loss: 0.539\n",
            "[1,  4720] loss: 0.493\n",
            "[1,  4730] loss: 0.698\n",
            "[1,  4740] loss: 0.518\n",
            "[1,  4750] loss: 0.457\n",
            "[1,  4760] loss: 0.678\n",
            "[1,  4770] loss: 0.523\n",
            "[1,  4780] loss: 0.451\n",
            "[1,  4790] loss: 0.562\n",
            "[1,  4800] loss: 0.470\n",
            "[1,  4810] loss: 0.544\n",
            "[1,  4820] loss: 0.600\n",
            "[1,  4830] loss: 0.705\n",
            "[1,  4840] loss: 0.570\n",
            "[1,  4850] loss: 0.568\n",
            "[1,  4860] loss: 0.679\n",
            "[1,  4870] loss: 0.644\n",
            "[1,  4880] loss: 0.539\n",
            "[1,  4890] loss: 0.603\n",
            "[1,  4900] loss: 0.728\n",
            "[1,  4910] loss: 0.843\n",
            "[1,  4920] loss: 0.855\n",
            "[1,  4930] loss: 0.626\n",
            "[1,  4940] loss: 0.787\n",
            "[1,  4950] loss: 0.591\n",
            "[1,  4960] loss: 0.569\n",
            "[1,  4970] loss: 0.452\n",
            "[1,  4980] loss: 0.562\n",
            "[1,  4990] loss: 0.554\n",
            "[1,  5000] loss: 0.879\n",
            "[1,  5010] loss: 0.732\n",
            "[1,  5020] loss: 0.708\n",
            "[1,  5030] loss: 0.565\n",
            "[1,  5040] loss: 0.723\n",
            "[1,  5050] loss: 0.518\n",
            "[1,  5060] loss: 0.808\n",
            "[1,  5070] loss: 0.699\n",
            "[1,  5080] loss: 0.612\n",
            "[1,  5090] loss: 0.533\n",
            "[1,  5100] loss: 0.554\n",
            "[1,  5110] loss: 0.697\n",
            "[1,  5120] loss: 0.466\n",
            "[1,  5130] loss: 0.441\n",
            "[1,  5140] loss: 0.515\n",
            "[1,  5150] loss: 0.440\n",
            "[1,  5160] loss: 0.489\n",
            "[1,  5170] loss: 0.512\n",
            "[1,  5180] loss: 0.502\n",
            "[1,  5190] loss: 0.904\n",
            "[1,  5200] loss: 0.876\n",
            "[1,  5210] loss: 0.551\n",
            "[1,  5220] loss: 0.516\n",
            "[1,  5230] loss: 0.618\n",
            "[1,  5240] loss: 0.442\n",
            "[1,  5250] loss: 0.600\n",
            "[1,  5260] loss: 0.403\n",
            "[1,  5270] loss: 0.587\n",
            "[1,  5280] loss: 0.505\n",
            "[1,  5290] loss: 0.591\n",
            "[1,  5300] loss: 0.517\n",
            "[1,  5310] loss: 0.873\n",
            "[1,  5320] loss: 0.681\n",
            "[1,  5330] loss: 0.859\n",
            "[1,  5340] loss: 0.711\n",
            "[1,  5350] loss: 0.535\n",
            "[1,  5360] loss: 0.688\n",
            "[1,  5370] loss: 0.715\n",
            "[1,  5380] loss: 0.263\n",
            "[1,  5390] loss: 0.673\n",
            "[1,  5400] loss: 0.718\n",
            "[1,  5410] loss: 0.597\n",
            "[1,  5420] loss: 0.618\n",
            "[1,  5430] loss: 0.533\n",
            "[1,  5440] loss: 0.412\n",
            "[1,  5450] loss: 0.791\n",
            "[1,  5460] loss: 0.405\n",
            "[1,  5470] loss: 0.522\n",
            "[1,  5480] loss: 0.518\n",
            "[1,  5490] loss: 0.482\n",
            "[1,  5500] loss: 0.684\n",
            "[1,  5510] loss: 0.642\n",
            "[1,  5520] loss: 0.542\n",
            "[1,  5530] loss: 0.295\n",
            "[1,  5540] loss: 0.530\n",
            "[1,  5550] loss: 0.763\n",
            "[1,  5560] loss: 0.633\n",
            "[1,  5570] loss: 0.495\n",
            "[1,  5580] loss: 0.581\n",
            "[1,  5590] loss: 0.582\n",
            "[1,  5600] loss: 0.510\n",
            "[1,  5610] loss: 0.419\n",
            "[1,  5620] loss: 0.374\n",
            "[1,  5630] loss: 0.724\n",
            "[1,  5640] loss: 0.710\n",
            "[1,  5650] loss: 0.965\n",
            "[1,  5660] loss: 0.488\n",
            "[1,  5670] loss: 0.465\n",
            "[1,  5680] loss: 0.387\n",
            "[1,  5690] loss: 0.526\n",
            "[1,  5700] loss: 0.570\n",
            "[1,  5710] loss: 0.598\n",
            "[1,  5720] loss: 0.564\n",
            "[1,  5730] loss: 0.514\n",
            "[1,  5740] loss: 0.415\n",
            "[1,  5750] loss: 0.527\n",
            "[1,  5760] loss: 0.550\n",
            "[1,  5770] loss: 0.586\n",
            "[1,  5780] loss: 0.451\n",
            "[1,  5790] loss: 0.633\n",
            "[1,  5800] loss: 0.649\n",
            "[1,  5810] loss: 0.340\n",
            "[1,  5820] loss: 0.766\n",
            "[1,  5830] loss: 0.443\n",
            "[1,  5840] loss: 0.610\n",
            "[1,  5850] loss: 0.431\n",
            "[1,  5860] loss: 0.611\n",
            "[1,  5870] loss: 0.674\n",
            "[1,  5880] loss: 0.639\n",
            "[1,  5890] loss: 0.538\n",
            "[1,  5900] loss: 0.606\n",
            "[1,  5910] loss: 0.442\n",
            "[1,  5920] loss: 0.565\n",
            "[1,  5930] loss: 0.510\n",
            "[1,  5940] loss: 0.583\n",
            "[1,  5950] loss: 0.604\n",
            "[1,  5960] loss: 0.527\n",
            "[1,  5970] loss: 0.579\n",
            "[1,  5980] loss: 0.599\n",
            "[1,  5990] loss: 0.549\n",
            "[1,  6000] loss: 0.488\n",
            "[1,  6010] loss: 0.638\n",
            "[1,  6020] loss: 0.604\n",
            "[1,  6030] loss: 0.669\n",
            "[1,  6040] loss: 0.417\n",
            "[1,  6050] loss: 0.711\n",
            "[1,  6060] loss: 0.506\n",
            "[1,  6070] loss: 0.717\n",
            "[1,  6080] loss: 0.429\n",
            "[1,  6090] loss: 0.630\n",
            "[1,  6100] loss: 0.404\n",
            "[1,  6110] loss: 0.470\n",
            "[1,  6120] loss: 0.488\n",
            "[1,  6130] loss: 0.511\n",
            "[1,  6140] loss: 0.662\n",
            "[1,  6150] loss: 0.241\n",
            "[1,  6160] loss: 0.463\n",
            "[1,  6170] loss: 0.354\n",
            "[1,  6180] loss: 0.374\n",
            "[1,  6190] loss: 0.580\n",
            "[1,  6200] loss: 0.423\n",
            "[1,  6210] loss: 0.744\n",
            "[1,  6220] loss: 0.729\n",
            "[1,  6230] loss: 0.730\n",
            "[1,  6240] loss: 0.495\n",
            "[1,  6250] loss: 0.654\n",
            "[1,  6260] loss: 0.447\n",
            "[1,  6270] loss: 0.520\n",
            "[1,  6280] loss: 0.889\n",
            "[1,  6290] loss: 0.609\n",
            "[1,  6300] loss: 0.609\n",
            "[1,  6310] loss: 0.380\n",
            "[1,  6320] loss: 0.441\n",
            "[1,  6330] loss: 0.458\n",
            "[1,  6340] loss: 0.448\n",
            "[1,  6350] loss: 0.382\n",
            "[1,  6360] loss: 0.452\n",
            "[1,  6370] loss: 0.484\n",
            "[1,  6380] loss: 0.362\n",
            "[1,  6390] loss: 0.235\n",
            "[1,  6400] loss: 0.396\n",
            "[1,  6410] loss: 0.826\n",
            "[1,  6420] loss: 0.616\n",
            "[1,  6430] loss: 0.366\n",
            "[1,  6440] loss: 0.526\n",
            "[1,  6450] loss: 0.530\n",
            "[1,  6460] loss: 0.481\n",
            "[1,  6470] loss: 0.384\n",
            "[1,  6480] loss: 0.500\n",
            "[1,  6490] loss: 0.639\n",
            "[1,  6500] loss: 0.535\n",
            "[1,  6510] loss: 0.444\n",
            "[1,  6520] loss: 0.314\n",
            "[1,  6530] loss: 0.387\n",
            "[1,  6540] loss: 0.580\n",
            "[1,  6550] loss: 0.462\n",
            "[1,  6560] loss: 0.398\n",
            "[1,  6570] loss: 0.546\n",
            "[1,  6580] loss: 0.432\n",
            "[1,  6590] loss: 0.765\n",
            "[1,  6600] loss: 0.576\n",
            "[1,  6610] loss: 0.889\n",
            "[1,  6620] loss: 0.580\n",
            "[1,  6630] loss: 0.491\n",
            "[1,  6640] loss: 0.528\n",
            "[1,  6650] loss: 0.460\n",
            "[1,  6660] loss: 0.740\n",
            "[1,  6670] loss: 0.732\n",
            "[1,  6680] loss: 0.532\n",
            "[1,  6690] loss: 0.480\n",
            "[1,  6700] loss: 0.374\n",
            "[1,  6710] loss: 0.589\n",
            "[1,  6720] loss: 0.467\n",
            "[1,  6730] loss: 0.619\n",
            "[1,  6740] loss: 0.619\n",
            "[1,  6750] loss: 0.605\n",
            "[1,  6760] loss: 0.444\n",
            "[1,  6770] loss: 0.506\n",
            "[1,  6780] loss: 0.525\n",
            "[1,  6790] loss: 0.504\n",
            "[1,  6800] loss: 0.403\n",
            "[1,  6810] loss: 0.425\n",
            "[1,  6820] loss: 0.426\n",
            "[1,  6830] loss: 0.613\n",
            "[1,  6840] loss: 0.538\n",
            "[1,  6850] loss: 0.431\n",
            "[1,  6860] loss: 0.542\n",
            "[1,  6870] loss: 0.676\n",
            "[1,  6880] loss: 0.559\n",
            "[1,  6890] loss: 0.414\n",
            "[1,  6900] loss: 0.739\n",
            "[1,  6910] loss: 0.720\n",
            "[1,  6920] loss: 0.494\n",
            "[1,  6930] loss: 0.390\n",
            "[1,  6940] loss: 0.358\n",
            "[1,  6950] loss: 0.456\n",
            "[1,  6960] loss: 0.508\n",
            "[1,  6970] loss: 0.548\n",
            "[1,  6980] loss: 0.476\n",
            "[1,  6990] loss: 0.542\n",
            "[1,  7000] loss: 0.776\n",
            "[1,  7010] loss: 0.757\n",
            "[1,  7020] loss: 0.710\n",
            "[1,  7030] loss: 0.463\n",
            "[1,  7040] loss: 0.433\n",
            "[1,  7050] loss: 0.593\n",
            "[1,  7060] loss: 0.654\n",
            "[1,  7070] loss: 0.404\n",
            "[1,  7080] loss: 0.540\n",
            "[1,  7090] loss: 0.392\n",
            "[1,  7100] loss: 0.365\n",
            "[1,  7110] loss: 0.610\n",
            "[1,  7120] loss: 0.864\n",
            "[1,  7130] loss: 0.492\n",
            "[1,  7140] loss: 0.495\n",
            "[1,  7150] loss: 0.275\n",
            "[1,  7160] loss: 0.336\n",
            "[1,  7170] loss: 0.440\n",
            "[1,  7180] loss: 0.531\n",
            "[1,  7190] loss: 0.547\n",
            "[1,  7200] loss: 0.268\n",
            "[1,  7210] loss: 0.461\n",
            "[1,  7220] loss: 0.556\n",
            "[1,  7230] loss: 0.501\n",
            "[1,  7240] loss: 0.287\n",
            "[1,  7250] loss: 0.412\n",
            "[1,  7260] loss: 0.502\n",
            "[1,  7270] loss: 0.515\n",
            "[1,  7280] loss: 0.455\n",
            "[1,  7290] loss: 0.639\n",
            "[1,  7300] loss: 0.639\n",
            "[1,  7310] loss: 0.354\n",
            "[1,  7320] loss: 0.533\n",
            "[2,    10] loss: 0.490\n",
            "[2,    20] loss: 0.340\n",
            "[2,    30] loss: 0.490\n",
            "[2,    40] loss: 0.351\n",
            "[2,    50] loss: 0.528\n",
            "[2,    60] loss: 0.398\n",
            "[2,    70] loss: 0.446\n",
            "[2,    80] loss: 0.426\n",
            "[2,    90] loss: 0.599\n",
            "[2,   100] loss: 0.582\n",
            "[2,   110] loss: 0.473\n",
            "[2,   120] loss: 0.624\n",
            "[2,   130] loss: 0.678\n",
            "[2,   140] loss: 0.380\n",
            "[2,   150] loss: 0.465\n",
            "[2,   160] loss: 0.440\n",
            "[2,   170] loss: 0.363\n",
            "[2,   180] loss: 0.422\n",
            "[2,   190] loss: 0.471\n",
            "[2,   200] loss: 0.512\n",
            "[2,   210] loss: 0.412\n",
            "[2,   220] loss: 0.409\n",
            "[2,   230] loss: 0.328\n",
            "[2,   240] loss: 0.421\n",
            "[2,   250] loss: 0.514\n",
            "[2,   260] loss: 0.521\n",
            "[2,   270] loss: 0.423\n",
            "[2,   280] loss: 0.364\n",
            "[2,   290] loss: 0.591\n",
            "[2,   300] loss: 0.611\n",
            "[2,   310] loss: 0.490\n",
            "[2,   320] loss: 0.511\n",
            "[2,   330] loss: 0.277\n",
            "[2,   340] loss: 0.316\n",
            "[2,   350] loss: 0.651\n",
            "[2,   360] loss: 0.560\n",
            "[2,   370] loss: 0.800\n",
            "[2,   380] loss: 0.750\n",
            "[2,   390] loss: 0.606\n",
            "[2,   400] loss: 0.362\n",
            "[2,   410] loss: 0.609\n",
            "[2,   420] loss: 0.339\n",
            "[2,   430] loss: 0.273\n",
            "[2,   440] loss: 0.383\n",
            "[2,   450] loss: 0.356\n",
            "[2,   460] loss: 0.490\n",
            "[2,   470] loss: 0.483\n",
            "[2,   480] loss: 0.658\n",
            "[2,   490] loss: 0.315\n",
            "[2,   500] loss: 0.346\n",
            "[2,   510] loss: 0.382\n",
            "[2,   520] loss: 0.589\n",
            "[2,   530] loss: 0.362\n",
            "[2,   540] loss: 0.617\n",
            "[2,   550] loss: 0.436\n",
            "[2,   560] loss: 0.437\n",
            "[2,   570] loss: 0.432\n",
            "[2,   580] loss: 0.469\n",
            "[2,   590] loss: 0.390\n",
            "[2,   600] loss: 0.688\n",
            "[2,   610] loss: 0.448\n",
            "[2,   620] loss: 0.597\n",
            "[2,   630] loss: 0.534\n",
            "[2,   640] loss: 0.467\n",
            "[2,   650] loss: 0.499\n",
            "[2,   660] loss: 0.534\n",
            "[2,   670] loss: 0.471\n",
            "[2,   680] loss: 0.522\n",
            "[2,   690] loss: 0.700\n",
            "[2,   700] loss: 0.446\n",
            "[2,   710] loss: 0.414\n",
            "[2,   720] loss: 0.540\n",
            "[2,   730] loss: 0.334\n",
            "[2,   740] loss: 0.798\n",
            "[2,   750] loss: 0.477\n",
            "[2,   760] loss: 0.476\n",
            "[2,   770] loss: 0.492\n",
            "[2,   780] loss: 0.510\n",
            "[2,   790] loss: 0.366\n",
            "[2,   800] loss: 0.449\n",
            "[2,   810] loss: 0.535\n",
            "[2,   820] loss: 0.469\n",
            "[2,   830] loss: 0.440\n",
            "[2,   840] loss: 0.303\n",
            "[2,   850] loss: 0.393\n",
            "[2,   860] loss: 0.401\n",
            "[2,   870] loss: 0.545\n",
            "[2,   880] loss: 0.506\n",
            "[2,   890] loss: 0.426\n",
            "[2,   900] loss: 0.552\n",
            "[2,   910] loss: 0.543\n",
            "[2,   920] loss: 0.647\n",
            "[2,   930] loss: 0.338\n",
            "[2,   940] loss: 0.508\n",
            "[2,   950] loss: 0.432\n",
            "[2,   960] loss: 0.490\n",
            "[2,   970] loss: 0.414\n",
            "[2,   980] loss: 0.425\n",
            "[2,   990] loss: 0.419\n",
            "[2,  1000] loss: 0.650\n",
            "[2,  1010] loss: 0.470\n",
            "[2,  1020] loss: 0.550\n",
            "[2,  1030] loss: 0.587\n",
            "[2,  1040] loss: 0.478\n",
            "[2,  1050] loss: 0.390\n",
            "[2,  1060] loss: 0.301\n",
            "[2,  1070] loss: 0.552\n",
            "[2,  1080] loss: 0.505\n",
            "[2,  1090] loss: 0.389\n",
            "[2,  1100] loss: 0.426\n",
            "[2,  1110] loss: 0.412\n",
            "[2,  1120] loss: 0.481\n",
            "[2,  1130] loss: 0.429\n",
            "[2,  1140] loss: 0.389\n",
            "[2,  1150] loss: 0.482\n",
            "[2,  1160] loss: 0.392\n",
            "[2,  1170] loss: 0.481\n",
            "[2,  1180] loss: 0.418\n",
            "[2,  1190] loss: 0.535\n",
            "[2,  1200] loss: 0.599\n",
            "[2,  1210] loss: 0.349\n",
            "[2,  1220] loss: 0.704\n",
            "[2,  1230] loss: 0.295\n",
            "[2,  1240] loss: 0.443\n",
            "[2,  1250] loss: 0.418\n",
            "[2,  1260] loss: 0.570\n",
            "[2,  1270] loss: 0.309\n",
            "[2,  1280] loss: 0.208\n",
            "[2,  1290] loss: 0.331\n",
            "[2,  1300] loss: 0.341\n",
            "[2,  1310] loss: 0.365\n",
            "[2,  1320] loss: 0.293\n",
            "[2,  1330] loss: 0.360\n",
            "[2,  1340] loss: 0.542\n",
            "[2,  1350] loss: 0.320\n",
            "[2,  1360] loss: 0.477\n",
            "[2,  1370] loss: 0.346\n",
            "[2,  1380] loss: 0.408\n",
            "[2,  1390] loss: 0.366\n",
            "[2,  1400] loss: 0.413\n",
            "[2,  1410] loss: 0.567\n",
            "[2,  1420] loss: 0.467\n",
            "[2,  1430] loss: 0.591\n",
            "[2,  1440] loss: 0.613\n",
            "[2,  1450] loss: 0.579\n",
            "[2,  1460] loss: 0.551\n",
            "[2,  1470] loss: 0.351\n",
            "[2,  1480] loss: 0.478\n",
            "[2,  1490] loss: 0.553\n",
            "[2,  1500] loss: 0.790\n",
            "[2,  1510] loss: 0.379\n",
            "[2,  1520] loss: 0.460\n",
            "[2,  1530] loss: 0.470\n",
            "[2,  1540] loss: 0.325\n",
            "[2,  1550] loss: 0.501\n",
            "[2,  1560] loss: 0.455\n",
            "[2,  1570] loss: 0.488\n",
            "[2,  1580] loss: 0.375\n",
            "[2,  1590] loss: 0.551\n",
            "[2,  1600] loss: 0.312\n",
            "[2,  1610] loss: 0.388\n",
            "[2,  1620] loss: 0.236\n",
            "[2,  1630] loss: 0.521\n",
            "[2,  1640] loss: 0.765\n",
            "[2,  1650] loss: 0.383\n",
            "[2,  1660] loss: 0.360\n",
            "[2,  1670] loss: 0.332\n",
            "[2,  1680] loss: 0.386\n",
            "[2,  1690] loss: 0.400\n",
            "[2,  1700] loss: 0.304\n",
            "[2,  1710] loss: 0.371\n",
            "[2,  1720] loss: 0.669\n",
            "[2,  1730] loss: 0.468\n",
            "[2,  1740] loss: 0.370\n",
            "[2,  1750] loss: 0.347\n",
            "[2,  1760] loss: 0.605\n",
            "[2,  1770] loss: 0.531\n",
            "[2,  1780] loss: 0.607\n",
            "[2,  1790] loss: 0.473\n",
            "[2,  1800] loss: 0.444\n",
            "[2,  1810] loss: 0.258\n",
            "[2,  1820] loss: 0.373\n",
            "[2,  1830] loss: 0.371\n",
            "[2,  1840] loss: 0.145\n",
            "[2,  1850] loss: 0.392\n",
            "[2,  1860] loss: 0.474\n",
            "[2,  1870] loss: 0.323\n",
            "[2,  1880] loss: 0.367\n",
            "[2,  1890] loss: 0.571\n",
            "[2,  1900] loss: 0.310\n",
            "[2,  1910] loss: 0.542\n",
            "[2,  1920] loss: 0.528\n",
            "[2,  1930] loss: 0.410\n",
            "[2,  1940] loss: 0.539\n",
            "[2,  1950] loss: 0.256\n",
            "[2,  1960] loss: 0.652\n",
            "[2,  1970] loss: 0.487\n",
            "[2,  1980] loss: 0.482\n",
            "[2,  1990] loss: 0.476\n",
            "[2,  2000] loss: 0.354\n",
            "[2,  2010] loss: 0.586\n",
            "[2,  2020] loss: 0.643\n",
            "[2,  2030] loss: 0.245\n",
            "[2,  2040] loss: 0.519\n",
            "[2,  2050] loss: 0.418\n",
            "[2,  2060] loss: 0.603\n",
            "[2,  2070] loss: 0.456\n",
            "[2,  2080] loss: 0.536\n",
            "[2,  2090] loss: 0.538\n",
            "[2,  2100] loss: 0.549\n",
            "[2,  2110] loss: 0.603\n",
            "[2,  2120] loss: 0.455\n",
            "[2,  2130] loss: 0.363\n",
            "[2,  2140] loss: 0.241\n",
            "[2,  2150] loss: 0.381\n",
            "[2,  2160] loss: 0.529\n",
            "[2,  2170] loss: 0.242\n",
            "[2,  2180] loss: 0.303\n",
            "[2,  2190] loss: 0.322\n",
            "[2,  2200] loss: 0.227\n",
            "[2,  2210] loss: 0.383\n",
            "[2,  2220] loss: 0.273\n",
            "[2,  2230] loss: 0.540\n",
            "[2,  2240] loss: 0.325\n",
            "[2,  2250] loss: 0.534\n",
            "[2,  2260] loss: 0.495\n",
            "[2,  2270] loss: 0.423\n",
            "[2,  2280] loss: 0.319\n",
            "[2,  2290] loss: 0.521\n",
            "[2,  2300] loss: 0.567\n",
            "[2,  2310] loss: 0.453\n",
            "[2,  2320] loss: 0.394\n",
            "[2,  2330] loss: 0.427\n",
            "[2,  2340] loss: 0.306\n",
            "[2,  2350] loss: 0.636\n",
            "[2,  2360] loss: 0.552\n",
            "[2,  2370] loss: 0.398\n",
            "[2,  2380] loss: 0.388\n",
            "[2,  2390] loss: 0.465\n",
            "[2,  2400] loss: 0.604\n",
            "[2,  2410] loss: 0.465\n",
            "[2,  2420] loss: 0.314\n",
            "[2,  2430] loss: 0.371\n",
            "[2,  2440] loss: 0.419\n",
            "[2,  2450] loss: 0.371\n",
            "[2,  2460] loss: 0.436\n",
            "[2,  2470] loss: 0.428\n",
            "[2,  2480] loss: 0.286\n",
            "[2,  2490] loss: 0.558\n",
            "[2,  2500] loss: 0.266\n",
            "[2,  2510] loss: 0.289\n",
            "[2,  2520] loss: 0.376\n",
            "[2,  2530] loss: 0.416\n",
            "[2,  2540] loss: 0.239\n",
            "[2,  2550] loss: 0.410\n",
            "[2,  2560] loss: 0.422\n",
            "[2,  2570] loss: 0.349\n",
            "[2,  2580] loss: 0.283\n",
            "[2,  2590] loss: 0.331\n",
            "[2,  2600] loss: 0.268\n",
            "[2,  2610] loss: 0.388\n",
            "[2,  2620] loss: 0.308\n",
            "[2,  2630] loss: 0.409\n",
            "[2,  2640] loss: 0.327\n",
            "[2,  2650] loss: 0.343\n",
            "[2,  2660] loss: 0.715\n",
            "[2,  2670] loss: 0.532\n",
            "[2,  2680] loss: 0.464\n",
            "[2,  2690] loss: 0.649\n",
            "[2,  2700] loss: 0.397\n",
            "[2,  2710] loss: 0.276\n",
            "[2,  2720] loss: 0.605\n",
            "[2,  2730] loss: 0.475\n",
            "[2,  2740] loss: 0.485\n",
            "[2,  2750] loss: 0.640\n",
            "[2,  2760] loss: 0.396\n",
            "[2,  2770] loss: 0.424\n",
            "[2,  2780] loss: 0.445\n",
            "[2,  2790] loss: 0.419\n",
            "[2,  2800] loss: 0.477\n",
            "[2,  2810] loss: 0.353\n",
            "[2,  2820] loss: 0.608\n",
            "[2,  2830] loss: 0.490\n",
            "[2,  2840] loss: 0.343\n",
            "[2,  2850] loss: 0.255\n",
            "[2,  2860] loss: 0.388\n",
            "[2,  2870] loss: 0.458\n",
            "[2,  2880] loss: 0.502\n",
            "[2,  2890] loss: 0.224\n",
            "[2,  2900] loss: 0.341\n",
            "[2,  2910] loss: 0.501\n",
            "[2,  2920] loss: 0.174\n",
            "[2,  2930] loss: 0.401\n",
            "[2,  2940] loss: 0.538\n",
            "[2,  2950] loss: 0.637\n",
            "[2,  2960] loss: 0.417\n",
            "[2,  2970] loss: 0.293\n",
            "[2,  2980] loss: 0.461\n",
            "[2,  2990] loss: 0.297\n",
            "[2,  3000] loss: 0.555\n",
            "[2,  3010] loss: 0.289\n",
            "[2,  3020] loss: 0.304\n",
            "[2,  3030] loss: 0.351\n",
            "[2,  3040] loss: 0.350\n",
            "[2,  3050] loss: 0.445\n",
            "[2,  3060] loss: 0.168\n",
            "[2,  3070] loss: 0.488\n",
            "[2,  3080] loss: 0.565\n",
            "[2,  3090] loss: 0.341\n",
            "[2,  3100] loss: 0.382\n",
            "[2,  3110] loss: 0.502\n",
            "[2,  3120] loss: 0.463\n",
            "[2,  3130] loss: 0.393\n",
            "[2,  3140] loss: 0.451\n",
            "[2,  3150] loss: 0.387\n",
            "[2,  3160] loss: 0.380\n",
            "[2,  3170] loss: 0.470\n",
            "[2,  3180] loss: 0.601\n",
            "[2,  3190] loss: 0.431\n",
            "[2,  3200] loss: 0.374\n",
            "[2,  3210] loss: 0.450\n",
            "[2,  3220] loss: 0.724\n",
            "[2,  3230] loss: 0.642\n",
            "[2,  3240] loss: 0.515\n",
            "[2,  3250] loss: 0.598\n",
            "[2,  3260] loss: 0.432\n",
            "[2,  3270] loss: 0.426\n",
            "[2,  3280] loss: 0.494\n",
            "[2,  3290] loss: 0.405\n",
            "[2,  3300] loss: 0.599\n",
            "[2,  3310] loss: 0.441\n",
            "[2,  3320] loss: 0.485\n",
            "[2,  3330] loss: 0.331\n",
            "[2,  3340] loss: 0.377\n",
            "[2,  3350] loss: 0.305\n",
            "[2,  3360] loss: 0.420\n",
            "[2,  3370] loss: 0.292\n",
            "[2,  3380] loss: 0.564\n",
            "[2,  3390] loss: 0.371\n",
            "[2,  3400] loss: 0.391\n",
            "[2,  3410] loss: 0.389\n",
            "[2,  3420] loss: 0.449\n",
            "[2,  3430] loss: 0.312\n",
            "[2,  3440] loss: 0.346\n",
            "[2,  3450] loss: 0.476\n",
            "[2,  3460] loss: 0.239\n",
            "[2,  3470] loss: 0.397\n",
            "[2,  3480] loss: 0.386\n",
            "[2,  3490] loss: 0.553\n",
            "[2,  3500] loss: 0.464\n",
            "[2,  3510] loss: 0.411\n",
            "[2,  3520] loss: 0.448\n",
            "[2,  3530] loss: 0.512\n",
            "[2,  3540] loss: 0.504\n",
            "[2,  3550] loss: 0.648\n",
            "[2,  3560] loss: 0.586\n",
            "[2,  3570] loss: 0.306\n",
            "[2,  3580] loss: 0.269\n",
            "[2,  3590] loss: 0.402\n",
            "[2,  3600] loss: 0.313\n",
            "[2,  3610] loss: 0.473\n",
            "[2,  3620] loss: 0.471\n",
            "[2,  3630] loss: 0.523\n",
            "[2,  3640] loss: 0.543\n",
            "[2,  3650] loss: 0.312\n",
            "[2,  3660] loss: 0.370\n",
            "[2,  3670] loss: 0.380\n",
            "[2,  3680] loss: 0.697\n",
            "[2,  3690] loss: 0.338\n",
            "[2,  3700] loss: 0.465\n",
            "[2,  3710] loss: 0.257\n",
            "[2,  3720] loss: 0.228\n",
            "[2,  3730] loss: 0.376\n",
            "[2,  3740] loss: 0.574\n",
            "[2,  3750] loss: 0.435\n",
            "[2,  3760] loss: 0.713\n",
            "[2,  3770] loss: 0.687\n",
            "[2,  3780] loss: 0.342\n",
            "[2,  3790] loss: 0.560\n",
            "[2,  3800] loss: 0.510\n",
            "[2,  3810] loss: 0.503\n",
            "[2,  3820] loss: 0.517\n",
            "[2,  3830] loss: 0.380\n",
            "[2,  3840] loss: 0.383\n",
            "[2,  3850] loss: 0.508\n",
            "[2,  3860] loss: 0.339\n",
            "[2,  3870] loss: 0.213\n",
            "[2,  3880] loss: 0.411\n",
            "[2,  3890] loss: 0.350\n",
            "[2,  3900] loss: 0.716\n",
            "[2,  3910] loss: 0.393\n",
            "[2,  3920] loss: 0.591\n",
            "[2,  3930] loss: 0.283\n",
            "[2,  3940] loss: 0.381\n",
            "[2,  3950] loss: 0.553\n",
            "[2,  3960] loss: 0.353\n",
            "[2,  3970] loss: 0.340\n",
            "[2,  3980] loss: 0.384\n",
            "[2,  3990] loss: 0.438\n",
            "[2,  4000] loss: 0.385\n",
            "[2,  4010] loss: 0.386\n",
            "[2,  4020] loss: 0.283\n",
            "[2,  4030] loss: 0.323\n",
            "[2,  4040] loss: 0.389\n",
            "[2,  4050] loss: 0.379\n",
            "[2,  4060] loss: 0.490\n",
            "[2,  4070] loss: 0.355\n",
            "[2,  4080] loss: 0.399\n",
            "[2,  4090] loss: 0.355\n",
            "[2,  4100] loss: 0.629\n",
            "[2,  4110] loss: 0.303\n",
            "[2,  4120] loss: 0.654\n",
            "[2,  4130] loss: 0.506\n",
            "[2,  4140] loss: 0.487\n",
            "[2,  4150] loss: 0.199\n",
            "[2,  4160] loss: 0.277\n",
            "[2,  4170] loss: 0.410\n",
            "[2,  4180] loss: 0.497\n",
            "[2,  4190] loss: 0.412\n",
            "[2,  4200] loss: 0.391\n",
            "[2,  4210] loss: 0.417\n",
            "[2,  4220] loss: 0.297\n",
            "[2,  4230] loss: 0.448\n",
            "[2,  4240] loss: 0.307\n",
            "[2,  4250] loss: 0.495\n",
            "[2,  4260] loss: 0.564\n",
            "[2,  4270] loss: 0.464\n",
            "[2,  4280] loss: 0.500\n",
            "[2,  4290] loss: 0.428\n",
            "[2,  4300] loss: 0.409\n",
            "[2,  4310] loss: 0.497\n",
            "[2,  4320] loss: 0.624\n",
            "[2,  4330] loss: 0.425\n",
            "[2,  4340] loss: 0.365\n",
            "[2,  4350] loss: 0.550\n",
            "[2,  4360] loss: 0.498\n",
            "[2,  4370] loss: 0.466\n",
            "[2,  4380] loss: 0.193\n",
            "[2,  4390] loss: 0.540\n",
            "[2,  4400] loss: 0.307\n",
            "[2,  4410] loss: 0.396\n",
            "[2,  4420] loss: 0.195\n",
            "[2,  4430] loss: 0.263\n",
            "[2,  4440] loss: 0.564\n",
            "[2,  4450] loss: 0.544\n",
            "[2,  4460] loss: 0.461\n",
            "[2,  4470] loss: 0.387\n",
            "[2,  4480] loss: 0.294\n",
            "[2,  4490] loss: 0.328\n",
            "[2,  4500] loss: 0.346\n",
            "[2,  4510] loss: 0.646\n",
            "[2,  4520] loss: 0.255\n",
            "[2,  4530] loss: 0.309\n",
            "[2,  4540] loss: 0.299\n",
            "[2,  4550] loss: 0.506\n",
            "[2,  4560] loss: 0.393\n",
            "[2,  4570] loss: 0.391\n",
            "[2,  4580] loss: 0.327\n",
            "[2,  4590] loss: 0.424\n",
            "[2,  4600] loss: 0.344\n",
            "[2,  4610] loss: 0.272\n",
            "[2,  4620] loss: 0.547\n",
            "[2,  4630] loss: 0.461\n",
            "[2,  4640] loss: 0.438\n",
            "[2,  4650] loss: 0.484\n",
            "[2,  4660] loss: 0.376\n",
            "[2,  4670] loss: 0.272\n",
            "[2,  4680] loss: 0.264\n",
            "[2,  4690] loss: 0.383\n",
            "[2,  4700] loss: 0.313\n",
            "[2,  4710] loss: 0.298\n",
            "[2,  4720] loss: 0.568\n",
            "[2,  4730] loss: 0.383\n",
            "[2,  4740] loss: 0.520\n",
            "[2,  4750] loss: 0.224\n",
            "[2,  4760] loss: 0.358\n",
            "[2,  4770] loss: 0.289\n",
            "[2,  4780] loss: 0.404\n",
            "[2,  4790] loss: 0.516\n",
            "[2,  4800] loss: 0.329\n",
            "[2,  4810] loss: 0.264\n",
            "[2,  4820] loss: 0.477\n",
            "[2,  4830] loss: 0.396\n",
            "[2,  4840] loss: 0.283\n",
            "[2,  4850] loss: 0.231\n",
            "[2,  4860] loss: 0.346\n",
            "[2,  4870] loss: 0.464\n",
            "[2,  4880] loss: 0.646\n",
            "[2,  4890] loss: 0.596\n",
            "[2,  4900] loss: 0.328\n",
            "[2,  4910] loss: 0.553\n",
            "[2,  4920] loss: 0.386\n",
            "[2,  4930] loss: 0.627\n",
            "[2,  4940] loss: 0.424\n",
            "[2,  4950] loss: 0.429\n",
            "[2,  4960] loss: 0.399\n",
            "[2,  4970] loss: 0.338\n",
            "[2,  4980] loss: 0.591\n",
            "[2,  4990] loss: 0.271\n",
            "[2,  5000] loss: 0.343\n",
            "[2,  5010] loss: 0.403\n",
            "[2,  5020] loss: 0.644\n",
            "[2,  5030] loss: 0.431\n",
            "[2,  5040] loss: 0.362\n",
            "[2,  5050] loss: 0.427\n",
            "[2,  5060] loss: 0.324\n",
            "[2,  5070] loss: 0.699\n",
            "[2,  5080] loss: 0.676\n",
            "[2,  5090] loss: 0.281\n",
            "[2,  5100] loss: 0.333\n",
            "[2,  5110] loss: 0.197\n",
            "[2,  5120] loss: 0.226\n",
            "[2,  5130] loss: 0.250\n",
            "[2,  5140] loss: 0.276\n",
            "[2,  5150] loss: 0.531\n",
            "[2,  5160] loss: 0.821\n",
            "[2,  5170] loss: 0.618\n",
            "[2,  5180] loss: 0.563\n",
            "[2,  5190] loss: 0.461\n",
            "[2,  5200] loss: 0.510\n",
            "[2,  5210] loss: 0.512\n",
            "[2,  5220] loss: 0.525\n",
            "[2,  5230] loss: 0.392\n",
            "[2,  5240] loss: 0.301\n",
            "[2,  5250] loss: 0.376\n",
            "[2,  5260] loss: 0.194\n",
            "[2,  5270] loss: 0.467\n",
            "[2,  5280] loss: 0.434\n",
            "[2,  5290] loss: 0.588\n",
            "[2,  5300] loss: 0.643\n",
            "[2,  5310] loss: 0.351\n",
            "[2,  5320] loss: 0.472\n",
            "[2,  5330] loss: 0.410\n",
            "[2,  5340] loss: 0.430\n",
            "[2,  5350] loss: 0.264\n",
            "[2,  5360] loss: 0.452\n",
            "[2,  5370] loss: 0.320\n",
            "[2,  5380] loss: 0.341\n",
            "[2,  5390] loss: 0.300\n",
            "[2,  5400] loss: 0.316\n",
            "[2,  5410] loss: 0.246\n",
            "[2,  5420] loss: 0.628\n",
            "[2,  5430] loss: 0.337\n",
            "[2,  5440] loss: 0.534\n",
            "[2,  5450] loss: 0.366\n",
            "[2,  5460] loss: 0.416\n",
            "[2,  5470] loss: 0.258\n",
            "[2,  5480] loss: 0.304\n",
            "[2,  5490] loss: 0.368\n",
            "[2,  5500] loss: 0.430\n",
            "[2,  5510] loss: 0.268\n",
            "[2,  5520] loss: 0.471\n",
            "[2,  5530] loss: 0.423\n",
            "[2,  5540] loss: 0.458\n",
            "[2,  5550] loss: 0.468\n",
            "[2,  5560] loss: 0.516\n",
            "[2,  5570] loss: 0.264\n",
            "[2,  5580] loss: 0.455\n",
            "[2,  5590] loss: 0.461\n",
            "[2,  5600] loss: 0.417\n",
            "[2,  5610] loss: 0.448\n",
            "[2,  5620] loss: 0.436\n",
            "[2,  5630] loss: 0.430\n",
            "[2,  5640] loss: 0.513\n",
            "[2,  5650] loss: 0.254\n",
            "[2,  5660] loss: 0.334\n",
            "[2,  5670] loss: 0.340\n",
            "[2,  5680] loss: 0.273\n",
            "[2,  5690] loss: 0.262\n",
            "[2,  5700] loss: 0.361\n",
            "[2,  5710] loss: 0.367\n",
            "[2,  5720] loss: 0.434\n",
            "[2,  5730] loss: 0.280\n",
            "[2,  5740] loss: 0.277\n",
            "[2,  5750] loss: 0.368\n",
            "[2,  5760] loss: 0.450\n",
            "[2,  5770] loss: 0.451\n",
            "[2,  5780] loss: 0.315\n",
            "[2,  5790] loss: 0.373\n",
            "[2,  5800] loss: 0.396\n",
            "[2,  5810] loss: 0.442\n",
            "[2,  5820] loss: 0.627\n",
            "[2,  5830] loss: 0.379\n",
            "[2,  5840] loss: 0.188\n",
            "[2,  5850] loss: 0.426\n",
            "[2,  5860] loss: 0.522\n",
            "[2,  5870] loss: 0.358\n",
            "[2,  5880] loss: 0.345\n",
            "[2,  5890] loss: 0.295\n",
            "[2,  5900] loss: 0.524\n",
            "[2,  5910] loss: 0.483\n",
            "[2,  5920] loss: 0.447\n",
            "[2,  5930] loss: 0.533\n",
            "[2,  5940] loss: 0.399\n",
            "[2,  5950] loss: 0.720\n",
            "[2,  5960] loss: 0.392\n",
            "[2,  5970] loss: 0.474\n",
            "[2,  5980] loss: 0.493\n",
            "[2,  5990] loss: 0.463\n",
            "[2,  6000] loss: 0.407\n",
            "[2,  6010] loss: 0.385\n",
            "[2,  6020] loss: 0.336\n",
            "[2,  6030] loss: 0.456\n",
            "[2,  6040] loss: 0.228\n",
            "[2,  6050] loss: 0.510\n",
            "[2,  6060] loss: 0.467\n",
            "[2,  6070] loss: 0.357\n",
            "[2,  6080] loss: 0.473\n",
            "[2,  6090] loss: 0.370\n",
            "[2,  6100] loss: 0.351\n",
            "[2,  6110] loss: 0.523\n",
            "[2,  6120] loss: 0.335\n",
            "[2,  6130] loss: 0.387\n",
            "[2,  6140] loss: 0.494\n",
            "[2,  6150] loss: 0.337\n",
            "[2,  6160] loss: 0.513\n",
            "[2,  6170] loss: 0.371\n",
            "[2,  6180] loss: 0.418\n",
            "[2,  6190] loss: 0.319\n",
            "[2,  6200] loss: 0.545\n",
            "[2,  6210] loss: 0.236\n",
            "[2,  6220] loss: 0.338\n",
            "[2,  6230] loss: 0.434\n",
            "[2,  6240] loss: 0.364\n",
            "[2,  6250] loss: 0.445\n",
            "[2,  6260] loss: 0.443\n",
            "[2,  6270] loss: 0.451\n",
            "[2,  6280] loss: 0.635\n",
            "[2,  6290] loss: 0.582\n",
            "[2,  6300] loss: 0.513\n",
            "[2,  6310] loss: 0.474\n",
            "[2,  6320] loss: 0.395\n",
            "[2,  6330] loss: 0.353\n",
            "[2,  6340] loss: 0.258\n",
            "[2,  6350] loss: 0.526\n",
            "[2,  6360] loss: 0.309\n",
            "[2,  6370] loss: 0.305\n",
            "[2,  6380] loss: 0.438\n",
            "[2,  6390] loss: 0.302\n",
            "[2,  6400] loss: 0.332\n",
            "[2,  6410] loss: 0.285\n",
            "[2,  6420] loss: 0.595\n",
            "[2,  6430] loss: 0.446\n",
            "[2,  6440] loss: 0.339\n",
            "[2,  6450] loss: 0.375\n",
            "[2,  6460] loss: 0.441\n",
            "[2,  6470] loss: 0.537\n",
            "[2,  6480] loss: 0.393\n",
            "[2,  6490] loss: 0.315\n",
            "[2,  6500] loss: 0.278\n",
            "[2,  6510] loss: 0.496\n",
            "[2,  6520] loss: 0.449\n",
            "[2,  6530] loss: 0.380\n",
            "[2,  6540] loss: 0.424\n",
            "[2,  6550] loss: 0.224\n",
            "[2,  6560] loss: 0.517\n",
            "[2,  6570] loss: 0.355\n",
            "[2,  6580] loss: 0.384\n",
            "[2,  6590] loss: 0.335\n",
            "[2,  6600] loss: 0.344\n",
            "[2,  6610] loss: 0.300\n",
            "[2,  6620] loss: 0.329\n",
            "[2,  6630] loss: 0.373\n",
            "[2,  6640] loss: 0.355\n",
            "[2,  6650] loss: 0.347\n",
            "[2,  6660] loss: 0.408\n",
            "[2,  6670] loss: 0.293\n",
            "[2,  6680] loss: 0.308\n",
            "[2,  6690] loss: 0.532\n",
            "[2,  6700] loss: 0.529\n",
            "[2,  6710] loss: 0.288\n",
            "[2,  6720] loss: 0.341\n",
            "[2,  6730] loss: 0.317\n",
            "[2,  6740] loss: 0.461\n",
            "[2,  6750] loss: 0.252\n",
            "[2,  6760] loss: 0.280\n",
            "[2,  6770] loss: 0.485\n",
            "[2,  6780] loss: 0.275\n",
            "[2,  6790] loss: 0.350\n",
            "[2,  6800] loss: 0.225\n",
            "[2,  6810] loss: 0.315\n",
            "[2,  6820] loss: 0.375\n",
            "[2,  6830] loss: 0.268\n",
            "[2,  6840] loss: 0.332\n",
            "[2,  6850] loss: 0.532\n",
            "[2,  6860] loss: 0.308\n",
            "[2,  6870] loss: 0.183\n",
            "[2,  6880] loss: 0.369\n",
            "[2,  6890] loss: 0.470\n",
            "[2,  6900] loss: 0.378\n",
            "[2,  6910] loss: 0.337\n",
            "[2,  6920] loss: 0.297\n",
            "[2,  6930] loss: 0.370\n",
            "[2,  6940] loss: 0.284\n",
            "[2,  6950] loss: 0.246\n",
            "[2,  6960] loss: 0.356\n",
            "[2,  6970] loss: 0.317\n",
            "[2,  6980] loss: 0.511\n",
            "[2,  6990] loss: 0.386\n",
            "[2,  7000] loss: 0.643\n",
            "[2,  7010] loss: 0.366\n",
            "[2,  7020] loss: 0.497\n",
            "[2,  7030] loss: 0.360\n",
            "[2,  7040] loss: 0.390\n",
            "[2,  7050] loss: 0.309\n",
            "[2,  7060] loss: 0.431\n",
            "[2,  7070] loss: 0.451\n",
            "[2,  7080] loss: 0.560\n",
            "[2,  7090] loss: 0.388\n",
            "[2,  7100] loss: 0.366\n",
            "[2,  7110] loss: 0.557\n",
            "[2,  7120] loss: 0.377\n",
            "[2,  7130] loss: 0.559\n",
            "[2,  7140] loss: 0.411\n",
            "[2,  7150] loss: 0.391\n",
            "[2,  7160] loss: 0.296\n",
            "[2,  7170] loss: 0.240\n",
            "[2,  7180] loss: 0.458\n",
            "[2,  7190] loss: 0.452\n",
            "[2,  7200] loss: 0.290\n",
            "[2,  7210] loss: 0.352\n",
            "[2,  7220] loss: 0.410\n",
            "[2,  7230] loss: 0.365\n",
            "[2,  7240] loss: 0.373\n",
            "[2,  7250] loss: 0.510\n",
            "[2,  7260] loss: 0.373\n",
            "[2,  7270] loss: 0.558\n",
            "[2,  7280] loss: 0.245\n",
            "[2,  7290] loss: 0.399\n",
            "[2,  7300] loss: 0.293\n",
            "[2,  7310] loss: 0.396\n",
            "[2,  7320] loss: 0.542\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvF_oKNuutaR"
      },
      "source": [
        "classes = ('0', '1', '2', '3',\n",
        "           '4', '5', '6', '7', '8', '9')\n",
        "\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_data:\n",
        "    images, labels = data \n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "    outputs = model(images)\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "    for label, prediction in zip(labels, predictions):\n",
        "      if label == prediction:\n",
        "        correct_pred[classes[label]] += 1\n",
        "      total_pred[classes[label]] += 1"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrkNN3YA_J7p",
        "outputId": "a5157752-9c6f-4166-a4c0-a0c40c11a5ee"
      },
      "source": [
        "for classname, correct_count in correct_pred.items():\n",
        "  accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "  print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname, accuracy))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for class 0     is: 87.7 %\n",
            "Accuracy for class 1     is: 91.4 %\n",
            "Accuracy for class 2     is: 91.9 %\n",
            "Accuracy for class 3     is: 86.1 %\n",
            "Accuracy for class 4     is: 90.6 %\n",
            "Accuracy for class 5     is: 90.8 %\n",
            "Accuracy for class 6     is: 85.5 %\n",
            "Accuracy for class 7     is: 93.4 %\n",
            "Accuracy for class 8     is: 79.0 %\n",
            "Accuracy for class 9     is: 91.3 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFdhXb9rAzrI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}